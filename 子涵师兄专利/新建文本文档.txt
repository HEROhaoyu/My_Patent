各位老师好，我是张宇老师组的卢浩宇同学，我的开题报告题目是：《面向高性能图计算的可重构计算架构研究》。
工作简介
在图计算任务中，图数据的幂律分布常常导致通用CPU/GPU处理器陷入性能瓶颈。一些专用图加速器通过采用单一的固定算法，来加速图计算的某一步骤。虽然可以提高整体性能，但是灵活性较差。粗粒度可重构阵列 (Coarse-grain reconfigurable arrays CGRA)，可以实现接近专用架构的高性能，同时保持了比肩通用架构的可编程性，逐渐成为了图计算领域的研究热点。但是CGRA的缺点在于， 仅对具有规则计算模式的应用程序有效，对于不规则的应用程序效率低下。
这里的不规则应用程序定义是：具有不可预测的访问模式和控制流。许多重要的工作负载都是不规则的应用程序：图形分析、稀疏线性代数（密集线性代数属于规则应用）、稀疏深度学习和数据库。

对此我提出了一种结合时分复用技术的CGRA的架构，它将线性程序分块处理，多个代码分块复用一个处理单元，根据处理单元负载动态调度，以解决图计算过程中的负载不均衡问题，达到了性能与可用性的平衡。
研究背景
CGRA是一种可重构的空间硬件加速器。通常包括一个二维的“功能单元”阵列，对应图上的一个个小方块，每个功能单元包含一个算数逻辑单元ALU，可以执行基本算术操作、逻辑操作，以及一些内存操作。还有小型寄存器文件 (RF) 作为临时数据存储。此外每个功能单元都通过交换器连接到它的邻居，并且可以将计算结果传输到选定的邻居单元。
CGRA是可编程的，在每个周期，每个功能单元的操作可以配置，他们生成的中间值传到那个邻居单元也可以配置。
计算时，可以在功能单元阵列中选择部分功能单元互连形成相对固定的计算通路，对应于图中红色路线。通过硬件运行时配置，调整通路上各功能单元的功能。数据流沿着计算通路流动时，通路上的各功能单元就会按照设定好的操作对数据进行一系列计算。从而既满足了可编程性，又实现了接近“专用电路”的计算性能。
 
接下来从软件可编程性和硬件可编程性两个维度分析了现有的处理架构。
左上角的通用处理器，软件可编程性强，使用灵活，但是架构被垄断，不具备硬件可编程性。而且图数据通常显示出极高的稀疏性，通用架构复杂的管道对于图分析来说太深和冗余，导致了很差的性能。
左下角的专用集成电路，虽然价格便宜，针对特定应用可以达到很高的计算效率，但是灵活性太差。
右下角的可编程逻辑器件，似乎具有很好的硬件可编程性，可以代替专用集成电路。但是门级可编程逻辑块的粒度过于精细，使得运算过程中内部电路关键路径长，主频没法做高，同时，会耗费大量功耗。此外软件可编程性也很差。
右上角的动态可重构芯片，又称为软件定义芯片，则博采众长，与通用处理器相比，它的硬件是可编程的，用户可以根据特定应用的需要修改计算通路，从而达到很高的性能。而与FPGA相比，它是编程重构了算数逻辑单元ALU的阵列而非逻辑门阵列，粒度更高，可编程性更好。
研究现状
CGRA是一个具有潜力的研究方向，也有大量工作围绕其展开。如SPU、Elastic CGRAs等工作把CGRA作为独立的加速器，ADRES等工作则将其作为集成在通用处理器的协处理器。但是这些工作仅适用于具有结构化访问模式和控制流的常规应用程序。而对于那些具有非规则化内存访问和控制流的应用程序不适用。这类程序有图形分析、稀疏线性代数、稀疏深度学习等。在面对缓存未命中等长延迟操作时，CGRA采用的策略就是延迟等待；所以即使缓存未命中的情况很少见，不规则的控制流也会导致负载不平衡，从而使大部分结构处于空闲状态。
Triggered Instructions提出在指令周期这一时间粒度进行时分复用。Triggered Instructions具有一系列处理单元，这些处理单元以队列的形式被组织起来，并通过对延迟不敏感的通道来进行通信。其中每一个处理单元各自拥有有限的指令集。处理单元每个执行周期，会从自己的备选指令中选择一个。Triggered Instructions通过这种周期级别的细粒度时分复用提高了架构的资源利用效率。代价是它的每个处理单元（不同文章中的处理单元的定义是不一样的） 比 CGRA 中的功能单元更复杂，并且时延非常高。Triggered Instructions在极细的粒度引入时分复用，而与之对应的另一个极端是：FPGA中的运行时重新配置 (RTR) 功能，用于在超出可用资源时进行时分复用配置。然而，它上面的时分粒度在数百微秒 [13]——而要容忍内存延迟或实现流水线负载均衡，一般需要数十个指令周期。两者的时间粒度相差太大。所以目前运行时重新配置，只在少数具有丰富数据并行性，可以很好地映射到空间架构的应用程序，例如排序和流式处理等。

总结现有的研究工作的弊端：
在空间架构中引入时分复用，可以达到更好的负载均衡，但是已有的工作在选择时分的粒度时，要么过小，要么过大，无法兼顾资源利用率和性能。
系统架构
我们的架构是在常规CGRA架构的基础上进行改进。单个常规CGRA模块的内部组成如下：它由绿色的功能模块和橙色的连接器模块相连，构成一个空间分布的功能网格，边缘的紫色部分则是它和其他模块通信的IO接口。放大每个功能单元可以发现，它包含一个ALU整数逻辑运算单元，能够处理一些满足机器字长的简单的操作，这点和通用处理器一样。它还包含少量的fused multiply-add（FMA）用以支持浮点工作负载。configuration cell作用是确定每个ALU逻辑运算单元的操作，同时通过指示功能模块和那些switch相连，来确定操作数据的传递路径。
单个CGRA有时会被用作一个小的功能单元或者是协处理器，来加速一些小的核心。然而，要使用CGRA自动处理整个算法，而不借助通用处理器作为中介，需要多处理单元架构。如图常规架构包含多个处理单元  ，每个处理元素都集成了 CGRA 结构、私有 L1 缓存和基于队列的通信机制。架构上所有处理单元共享一个LLC缓存。此外还有控制核心负责进行调度。这里还是做下区分，一个包含CGRA的小核心，称为处理单元。CGRA中的功能网格部分，称为功能单元。

如图是我设计的改进的多处理单元架构，图中用虚线框起来的白色部分是我新增的硬件单元。主要包括：红色部分是一个调度器，用来根据处理单元的负载以及分块代码的任务量，将分块后的代码映射到相应的处理单元。中间是一个高速队列存储，用来存储数据，为控制流提供支持，以及为通道通信提供支持。紫色部分处理单元内部的通信队列和处理单元之间的通信队列。用于支持块内通信和块间通信。通过改进的多处理单元架构，可以对CGRA实现较好的时分复用。
方案设计
那么上述架构是如何运行的呢？
我将根据这五个问题展开介绍：
1，如何实现对CGRA的时分复用？
为了应对不规则应用程序导致的负载不均衡问题，我引入了时分复用技术，将多个分块映射到同一个处理单元。调度器会根据处理单元的负载调度分块的执行，从而确保各个处理单元之间的负载是大致均衡的。但是不同分块往往需要空间架构提供不同的操作，要复用同一空间架构对不同分块进行处理操作，就需要对CGRA重新配置，从而确保数据被正确处理。
重配置过程分为三个步骤：1，载入新配置到缓存。2，将当前运行的分块的配置清零。3，激活新配置。
为了加速重配置的过程，我设计了一个双缓存配置单元，支持步骤一和步骤二并行进行。
如图，CGRA中原本在处理分块3，现在需要按照时分复用的要求切换到分块2的处理。相应的CGRA的配置也需要从分块3的配置切换到分块2的配置。当调度器接收到重配置指令，分块3立刻停止接受新的的输入，并且开始重置当前正在运行的操作，同时双缓存配置单元控制着分块2的操作并行载入。这样的并行举措相当于将重配置的操作步骤由3步缩减为了2步。而一旦残留的旧分块操作执行完，新的配置被加载完毕，f就会激活新配置，执行新的分块。

2，如何针对处理单元进行调度？
新架构里每个处理单元都增添了一个调度器，他可以使处理单元的配置在不同代码分块的配置之间动态切换。将哪个分块调度到特定处理单元取决于哪些输入队列具有可用值以及哪些输出队列有空间。
为了保持高利用率并分摊重新配置的总体成本，调度程序遵循一个简单的策略。
首先，它将处理单元配置为当前阶段分块所要求的配置，并尽可能延续该配置的寿命，直到它的输出队列已满或输入队列为空造成阻塞。此时，它不得不切换到一个新的分块来执行。而调度器会检查所有候选分块中的队列的占用情况。并候选分块即输入队列不为空，且输出队列不满的分块。调度器会选择其中输入队列中可用工作量最大的分块。这样就可以尽可能延长处理单元每次重配置后的使用寿命，从而减少了重新配置的次数。
3，如何支持处理单元上的不同分块间的通信？
这里的通信分为：同一处理单元内部通信，以及不同处理单元之间通信。
处理单元之间的通信：各单元之前通过一个先进先出的队列相互通信，这个队列通过灵活的接口实现。结构边缘的交换器可以从输入队列中弹出数据，然后压入到输出队列中。队列存储在每个处理单元中的一个小队列内存中（在我们的实现中是一个 16 KB SRAM）。该队列内存可以静态地划分为多个队列，每个队列都作为一个循环缓冲区进行管理处理单元之间的通信是解耦的，因此当一个处理单元发生阻塞时（例如，由于缓存未命中），其他处理单元不一定会停顿。
同一处理单元不同时刻的分块代码互相通信：由于生产者阶段与可能位于同一处理单元的消费者阶段进行通信，所以我们引入了处理单元内部队列。前面说了队列缓冲区可以被划分为多个队列，这里我们用更多的头/尾指针来扩充这个队列缓冲区，以存储这些额外的队列。这些 处理单元内的队列给在位于同一处理单元上不同分块提供高带宽通信，因此分离应用程序以便频繁通信的阶段驻留在同一处理单元上是有利的。当然，和以前一样，一个处理单元上的生产者阶段也可以向队列送入发往其它处理单元上的消费者阶段的数据。
4，如何传递处理单元上的控制信息？
有时，生产者可能需要将控制流决策传达给下游消费者阶段。在这种情况下，生产者可能会将控制值排入队列，这些值不能被误认为数据。
我们通过向通信通道和缓冲区添加一个额外的控制位来实现控制值，如图所示，以指示该值是否为控制值。我们类似地扩充功能单元以允许对控制值进行特殊处理：
控制值的应用：它可用于在操作数 A 或 B 之间进行选择，或用于谓词操作，例如，是否将特定值入队。控制位与数据一起传输；这样，它们的顺序可用于描绘数据集之间的边界或描绘迭代。随控制位传输的数据也可用于区分不同的条件（例如，迭代结束与程序结束）
5，如何进一步提高并行度?
处理单元中的（单指令多数据） SIMD 式并行：前面说过形成计算通路时，其实只使用了部分功能单元来形成计算通路。那么在计算任务比较简单时就会有很多空闲的功能单元。此时我们可以对功能单元网格进一步划分，例如，一个 4 × 4 的功能单元网格可以划分为4个2 × 2的网格，每个网格都运行一条小的数据通路，从而产生潜在的 4 倍吞吐量改进。提供了大量利用 SIMD 式并行性的机会：例如，图形应用程序执行的许多边缘列表访问可以并行启动。这些数据路径以同步方式运行：如果多个输入元素同时可用，它们可以作为一个组出列并同时处理，直到复制数据路径的数量。控制值始终按顺序处理：在给定周期中，PE 可以使多个数据值出队，但总是使单个控制值出队。
创新与挑战
通过以上内容，我讲解了如何利用改进的CGRA架构实现时分复用，这项工作的创新点在于为CGRA引入时分复用技术，将多个分块映射到的一个处理单元上，避免了负载不均衡。并通过double-buffered cell巧妙设计，减少了切换分块时的开销。同时设计为时分复用CGRA设计了调度策略、通信策略、控制策略、并行策略提高了架构的可用性。
同时它也面临一些挑战，主要是如何减少CGRA重配置的开销。如何对不同应用分块动态调度，减少开销。

验收指标与进度安排
接下来是我的工作安排：
我计划在
……
参考文献
最后是本次开题报告的参考文献。
致谢
以上就是我的开题报告的全部内容，敬请各位老师批评指正。